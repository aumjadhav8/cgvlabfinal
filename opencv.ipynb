{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc3fb8-d8c3-4799-8fc6-cdf7a9e2ab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread('faces4.jpeg')\n",
    "\n",
    "# Get the height and width of the image\n",
    "height, width = img.shape[:2]\n",
    "\n",
    "# Split the image into four quadrants\n",
    "quad1 = img[:height//2, :width//2]\n",
    "quad2 = img[:height//2, width//2:]\n",
    "quad3 = img[height//2:, :width//2]\n",
    "quad4 = img[height//2:, width//2:]\n",
    "\n",
    "# Store the quadrants in a list\n",
    "quadrants = [quad1, quad2, quad3, quad4]\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(cv2.cvtColor(quad1, cv2.COLOR_BGR2RGB))\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(cv2.cvtColor(quad2, cv2.COLOR_BGR2RGB))\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(cv2.cvtColor(quad3, cv2.COLOR_BGR2RGB))\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(cv2.cvtColor(quad4, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b17d70-f413-4a1f-859f-730a53ac527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lab program 8\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def translate_image(image, dx, dy):\n",
    "    rows, cols = image.shape[:2]\n",
    "    translation_matrix = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "    translated_image = cv2.warpAffine(image, translation_matrix, (cols, rows))\n",
    "    return translated_image\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread('faces4.jpeg')\n",
    "\n",
    "# Get image dimensions\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Calculate the center coordinates of the image\n",
    "center = (width // 2, height // 2)\n",
    "\n",
    "# Get user inputs\n",
    "rotation_value = int(input(\"Enter the degree of Rotation: \"))\n",
    "scaling_value = float(input(\"Enter the zooming factor: \"))\n",
    "h = int(input(\"How many pixels you want the image to be translated horizontally? \"))\n",
    "v = int(input(\"How many pixels you want the image to be translated vertically? \"))\n",
    "\n",
    "# Rotate the image\n",
    "rotation_matrix = cv2.getRotationMatrix2D(center=center, angle=rotation_value, scale=1)\n",
    "rotated_image = cv2.warpAffine(src=image, M=rotation_matrix, dsize=(width, height))\n",
    "\n",
    "# Scale the image\n",
    "scaled_matrix = cv2.getRotationMatrix2D(center=center, angle=0, scale=scaling_value)\n",
    "scaled_image = cv2.warpAffine(src=rotated_image, M=scaled_matrix, dsize=(width, height))\n",
    "\n",
    "# Translate the image\n",
    "translated_image = translate_image(scaled_image, dx=h, dy=v)\n",
    "\n",
    "# Save and display the final image\n",
    "cv2.imwrite('Final_image.png', translated_image)\n",
    "\n",
    "# Display the results\n",
    "cv2.imshow(\"Final Transformed Image\", translated_image)\n",
    "\n",
    "# Wait for a key press and then close all windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a9b234-c30d-4abd-83bf-06afba87f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lab program 9\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image_path = \"faces4.jpeg\"  # Replace with the path to your image\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Edge detection\n",
    "edges = cv2.Canny(gray, 100, 200)  # Use Canny edge detector\n",
    "\n",
    "# Texture extraction\n",
    "kernel = np.ones((5, 5), np.float32) / 25  # Define a 5x5 averaging kernel\n",
    "texture = cv2.filter2D(gray, -1, kernel)  # Apply the averaging filter for texture extraction\n",
    "\n",
    "# Display the original image, edges, and texture\n",
    "cv2.imshow(\"Original Image\", img)\n",
    "cv2.imshow(\"Edges\", edges)\n",
    "cv2.imshow(\"Texture\", texture)\n",
    "\n",
    "# Wait for a key press and then close all windows\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faead90-dd8b-40bf-b365-ccdf5ea59256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lab program 10\n",
    "import numpy as np \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "img=cv2.imread('faces4.jpeg',cv2.IMREAD_GRAYSCALE)\n",
    "image_array = np.array(img)\n",
    "print(image_array)\n",
    "def sharpen():\n",
    "  return np.array([[1,1,1],[1,1,1],[1,1,1]])\n",
    "def filtering(image, kernel):\n",
    "    m, n = kernel.shape\n",
    "    if (m == n):\n",
    "        y, x = image.shape[:2]\n",
    "        y = y - m + 1 # shape of image - shape of kernel + 1\n",
    "        x = x - m + 1\n",
    "        new_image = np.zeros((y,x))\n",
    "        for i in range(y):\n",
    "            for j in range(x):\n",
    "                new_image[i][j] = np.sum(image[i:i+m, j:j+m]*kernel)\n",
    "    return new_image\n",
    "# Display the original and sharpened images\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image_array,cmap='gray')\n",
    "plt.title(\"Original Grayscale Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(filtering(image_array, sharpen()),cmap='gray')\n",
    "plt.title(\"Blurred Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748a62ed-7db9-417b-bf4f-1eec5c0b1602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lab program 11\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the image\n",
    "image_path = 'faces4.jpeg'  # Update with your image path\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply binary thresholding\n",
    "_, binary_image = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw contours on the original image\n",
    "cv2.drawContours(image, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Convert the image from BGR to RGB format for displaying with matplotlib\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the result using matplotlib\n",
    "plt.imshow(image_rgb)\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569128cf-9030-44bd-9741-4ae3086518ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lab program 12\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the pre-trained Haar Cascade classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Read the input image\n",
    "image_path = 'faces4.jpeg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces in the image\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "# Draw rectangles around detected faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "# Convert the image from BGR to RGB format for displaying with matplotlib\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the result using matplotlib\n",
    "plt.imshow(image_rgb)\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
